{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "633b8640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:30:11.922965Z",
     "start_time": "2021-12-26T14:30:11.920974Z"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01dce327",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:30:12.099726Z",
     "start_time": "2021-12-26T14:30:12.092229Z"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v1')\n",
    "MAX_STEP_PER_EPISODE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bbfe9e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:30:12.291994Z",
     "start_time": "2021-12-26T14:30:12.288678Z"
    }
   },
   "outputs": [],
   "source": [
    "def target_policy(q_function,state):\n",
    "    action = np.zeros_like(q_function[state])\n",
    "    optimal = np.argmax(q_function[state])\n",
    "    action[optimal] = 1.0\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d8d3e53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:30:12.664595Z",
     "start_time": "2021-12-26T14:30:12.658705Z"
    }
   },
   "outputs": [],
   "source": [
    "def behavior_policy(env, state):\n",
    "    return np.ones(env.nA) / env.nA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f3c7ddb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:34:26.379504Z",
     "start_time": "2021-12-26T14:34:26.375174Z"
    }
   },
   "outputs": [],
   "source": [
    "def off_policy_mc(env = env, \n",
    "                  behavior_policy=behavior_policy, \n",
    "                  target_policy = target_policy, \n",
    "                  episodes = 50000, \n",
    "                  discount = 1.0):\n",
    "    \"\"\"\n",
    "    Apply off-policy Monte Carlo method with importance sampling to find optimal policy\n",
    "    \n",
    "    Args:\n",
    "        env: environment\n",
    "        behavior_policy: a function takes q and state, return the soft probs of actions\n",
    "        target_policy: a function takes env and state, return the greedy probs of actions\n",
    "        episodes: number of episodes\n",
    "        discount: discount factor\n",
    "        \n",
    "    Return:\n",
    "        Q: Action-State function\n",
    "        \n",
    "    \"\"\"\n",
    "    #RL: an intro page 110 and 111\n",
    "    Q = np.zeros((env.nS, env.nA))\n",
    "    C = np.zeros((env.nS, env.nA))\n",
    "    \n",
    "    for epi in range(1, episodes + 1):\n",
    "        episode = []\n",
    "        state = env.reset()\n",
    "        for t in range(MAX_STEP_PER_EPISODE):\n",
    "            prob = behavior_policy(env, state)\n",
    "            action = np.random.choice(np.arange(env.nA), p=prob)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            episode.append((state, action, reward))\n",
    "            if done:\n",
    "                break\n",
    "            state = next_state\n",
    "        \n",
    "        \n",
    "        G = 0\n",
    "        W = 1.0\n",
    "        \n",
    "        for t in range(len(episode) - 1, -1, -1):\n",
    "            state, action, reward = episode[t];\n",
    "            G = discount * G + reward\n",
    "            C[state][action] += W\n",
    "            Q[state][action] += W / C[state][action] * (G - Q[state][action])\n",
    "            \n",
    "            # if the action taken would not be taken by target policy\n",
    "            # the prob is zero, therefore break here\n",
    "            if action != np.argmax(target_policy(Q, state)):\n",
    "                break\n",
    "            \n",
    "            W *= 1.0 / behavior_policy(env, state)[action]\n",
    "    return Q\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "134f13a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:34:38.149184Z",
     "start_time": "2021-12-26T14:34:26.571755Z"
    }
   },
   "outputs": [],
   "source": [
    "q = off_policy_mc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8faa659",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:34:38.159927Z",
     "start_time": "2021-12-26T14:34:38.157810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a61ca46f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T14:34:38.168002Z",
     "start_time": "2021-12-26T14:34:38.165878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99999967 0.99999917 0.99999695 0.        ]\n",
      " [0.9994627  0.         0.52557485 0.        ]\n",
      " [0.99929385 0.99539226 0.59722222 0.        ]\n",
      " [0.         0.96106195 0.95675676 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "value = np.zeros(env.nS)\n",
    "for i in range(env.nS):\n",
    "    value[i] = np.max(q[i])\n",
    "print(value.reshape(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660285f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
